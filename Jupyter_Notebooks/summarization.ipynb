{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-zmmgGe8TSU"
      },
      "outputs": [],
      "source": [
        "# Run this first, Comment it, restart session and run all.\n",
        "# !pip install accelerate -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVm8REXZ0Wil"
      },
      "outputs": [],
      "source": [
        "# #To connect google drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-JkSAHyk9aW8"
      },
      "outputs": [],
      "source": [
        "OUT_DIR = '/content/test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HiyU3vIT0n4z"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "seed=22"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWa8z3xz00Wb"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('./rt_reviews_data_2k.csv')\n",
        "\n",
        "data=data.drop(['Prompt','title'], axis=1)\n",
        "data=data.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ndhn-e5L1aii"
      },
      "outputs": [],
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "import glob\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
        "model = T5ForConditionalGeneration.from_pretrained('t5-base')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJBkM_ld1gH4"
      },
      "outputs": [],
      "source": [
        "def summarize_text(text, model, tokenizer, max_length=800, num_beams=5):\n",
        "    # Preprocess the text\n",
        "    inputs = tokenizer.encode(\n",
        "        \"summarize: \" + text,\n",
        "        return_tensors='pt',\n",
        "        max_length=max_length,\n",
        "        truncation=True\n",
        "    )\n",
        "\n",
        "    # Generate the summary\n",
        "    summary_ids = model.generate(\n",
        "        inputs,\n",
        "        max_length=150,\n",
        "        num_beams=num_beams,\n",
        "        # early_stopping=True,\n",
        "    )\n",
        "\n",
        "    # Decode and return the summary\n",
        "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Saa3aMB-28z1"
      },
      "outputs": [],
      "source": [
        "# !pip install -U transformers\n",
        "# !pip install -U datasets\n",
        "# !pip install tensorboard\n",
        "# !pip install sentencepiece\n",
        "# !pip install accelerate\n",
        "# !pip install evaluate\n",
        "# !pip install rouge_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RyLpeDrT2_fp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pprint\n",
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "from transformers import (\n",
        "    T5Tokenizer,\n",
        "    T5ForConditionalGeneration,\n",
        "    TrainingArguments,\n",
        "    Trainer\n",
        ")\n",
        "import datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0Nci7Wc3Soa"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data['reviewText'],data['summary'],test_size=0.2, shuffle=True, random_state=seed)\n",
        "\n",
        "dataset_train={'reviewText':X_train, 'summary':y_train}\n",
        "dataset_test={'reviewText':X_test, 'summary':y_test}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQfERweM5wt1"
      },
      "outputs": [],
      "source": [
        "dataset_train=datasets.Dataset.from_pandas(pd.DataFrame(data=dataset_train))\n",
        "dataset_test=datasets.Dataset.from_pandas(pd.DataFrame(data=dataset_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oT76aGxZ37gq"
      },
      "outputs": [],
      "source": [
        "MODEL = 't5-base'\n",
        "BATCH_SIZE = 4\n",
        "NUM_PROCS = 4\n",
        "EPOCHS = 10\n",
        "MAX_LENGTH = 800"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6JHBDVa4CT5"
      },
      "outputs": [],
      "source": [
        "tokenizer = T5Tokenizer.from_pretrained(MODEL)\n",
        "\n",
        "# Function to convert text data into model inputs and targets\n",
        "def preprocess_function(examples):\n",
        "    inputs = [f\"summarize: {article}\" for article in examples['reviewText']]\n",
        "    model_inputs = tokenizer(\n",
        "        inputs,\n",
        "        max_length=MAX_LENGTH,\n",
        "        truncation=True,\n",
        "        padding='max_length'\n",
        "    )\n",
        "\n",
        "    # Set up the tokenizer for targets\n",
        "    targets = [summary for summary in examples['summary']]\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(\n",
        "            targets,\n",
        "            max_length=MAX_LENGTH,\n",
        "            truncation=True,\n",
        "            padding='max_length'\n",
        "        )\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "# Apply the function to the whole dataset\n",
        "tokenized_train = dataset_train.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    num_proc=NUM_PROCS\n",
        ")\n",
        "tokenized_test = dataset_test.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    num_proc=NUM_PROCS\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNZc-upL4GSX"
      },
      "outputs": [],
      "source": [
        "model = T5ForConditionalGeneration.from_pretrained(MODEL)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "# Total parameters and trainable parameters.\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"{total_params:,} total parameters.\")\n",
        "total_trainable_params = sum(\n",
        "    p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"{total_trainable_params:,} training parameters.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bh7t_gK24IRc"
      },
      "outputs": [],
      "source": [
        "rouge = evaluate.load(\"rouge\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred.predictions[0], eval_pred.label_ids\n",
        "\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    result = rouge.compute(\n",
        "        predictions=decoded_preds,\n",
        "        references=decoded_labels,\n",
        "        use_stemmer=True,\n",
        "        rouge_types=[\n",
        "            'rouge1',\n",
        "            'rouge2',\n",
        "            'rougeL'\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "\n",
        "    return {k: round(v, 4) for k, v in result.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Er4_2VT4KKF"
      },
      "outputs": [],
      "source": [
        "def preprocess_logits_for_metrics(logits, labels):\n",
        "    pred_ids = torch.argmax(logits[0], dim=-1)\n",
        "    return pred_ids, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0SNRiKtThI3",
        "outputId": "5ca857af-e730-4e8e-dcf9-e17ff7c3a786"
      },
      "outputs": [],
      "source": [
        "%env PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udOh2U_24OBK"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=OUT_DIR,\n",
        "    num_train_epochs=EPOCHS,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=OUT_DIR,\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy='steps',\n",
        "    eval_steps=200,\n",
        "    save_strategy='epoch',\n",
        "    save_total_limit=2,\n",
        "    report_to='tensorboard',\n",
        "    learning_rate=0.0001,\n",
        "    dataloader_num_workers=4,\n",
        "        eval_accumulation_steps = 1,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_test,\n",
        "    preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1SX--EFySn74"
      },
      "outputs": [],
      "source": [
        "history = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BR5q1-NU4TbQ"
      },
      "outputs": [],
      "source": [
        "model_path = f\"{OUT_DIR}/checkpoint-2000\"  # the path where you saved your model\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_path)\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-base')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCak98BQXqlT"
      },
      "outputs": [],
      "source": [
        "# !huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2upb83NXtRF"
      },
      "outputs": [],
      "source": [
        "# model.push_to_hub(\"movie_reviews_trained_t5_checkpoint_2000_2024_03_29\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
